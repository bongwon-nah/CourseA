{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6396d23c-acd8-47b8-b5e1-475fb85cb196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_2209/3581220478.py:12: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "# BGE M3 임베딩 모델 설정\n",
    "embedding_model_name = \"../bge-m3\"\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    model_kwargs={'device': 'cuda' if torch.cuda.is_available() else 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "472558ac-02b6-4799-99d4-c64d02e15088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "# Qwen2.5-1.5B-Instruct 모델 설정\n",
    "model_name = \"../Qwen2.5-1.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea99e18-712e-4796-a2fa-cb4f92ca1182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/tmp/ipykernel_2209/1560324597.py:12: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 텍스트 생성 파이프라인 설정\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.15\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "def create_rag_pipeline(pdf_path):\n",
    "    # PDF 문서 로드\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # 텍스트 분할\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # 벡터 저장소 생성\n",
    "    vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "    \n",
    "    # RAG 체인 생성\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    \n",
    "    return qa_chain\n",
    "\n",
    "def query_rag_pipeline(qa_chain, question):\n",
    "    result = qa_chain({\"query\": question})\n",
    "    return {\n",
    "        \"answer\": result[\"result\"],\n",
    "        \"source_documents\": result[\"source_documents\"]\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a891d48-4f2f-4ad3-8129-74746c4a3100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "{context}\n",
      "\n",
      "Question: {question}\n",
      "Helpful Answer:\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"sample.pdf\"\n",
    "\n",
    "# RAG 파이프라인 생성\n",
    "qa_chain = create_rag_pipeline(pdf_path)\n",
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "315b7fb9-fb9c-4ea6-9820-87630ea96ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2209/1560324597.py:40: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": question})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "adaptation of BERT and performance on downstream\n",
      "document classification: Insights from social media.\n",
      "In Findings of the Association for Computational\n",
      "Linguistics: EMNLP 2021, pages 2400–2412, Punta\n",
      "Cana, Dominican Republic. Association for Compu-\n",
      "tational Linguistics.\n",
      "Devendra Singh Sachan, Siva Reddy, William L. Hamil-\n",
      "ton, Chris Dyer, and Dani Yogatama. 2021. End-to-\n",
      "end training of multi-document reader and retriever\n",
      "for open-domain question answering. In Advances\n",
      "in Neural Information Processing Systems 34: An-\n",
      "nual Conference on Neural Information Processing\n",
      "Systems 2021, NeurIPS 2021, December 6-14, 2021,\n",
      "virtual, pages 25968–25981.\n",
      "Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta\n",
      "Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola\n",
      "Cancedda, and Thomas Scialom. 2023. Toolformer:\n",
      "\n",
      "model is tuned for better LLM input contexts. An-\n",
      "other research line focuses on the design of inter-\n",
      "actions between the retriever and the reader (Yao\n",
      "et al., 2023; Khattab et al., 2022), where both the\n",
      "arXiv:2305.14283v3  [cs.CL]  23 Oct 2023\n",
      "\n",
      "arXiv:1707.06347.\n",
      "Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li,\n",
      "Weiming Lu, and Yueting Zhuang. 2023. Hugging-\n",
      "gpt: Solving ai tasks with chatgpt and its friends in\n",
      "huggingface. arXiv preprint arXiv:2303.17580.\n",
      "Weijia Shi, Sewon Min, Michihiro Yasunaga, Min-\n",
      "joon Seo, Rich James, Mike Lewis, Luke Zettle-\n",
      "moyer, and Wen-tau Yih. 2023. Replug: Retrieval-\n",
      "augmented black-box language models. arXiv\n",
      "preprint arXiv:2301.12652.\n",
      "Kurt Shuster, Mojtaba Komeili, Leonard Adolphs,\n",
      "Stephen Roller, Arthur Szlam, and Jason Weston.\n",
      "2022. Language models that seek for knowledge:\n",
      "Modular search & generation for dialogue and\n",
      "prompt completion. In Findings of the Association\n",
      "for Computational Linguistics: EMNLP 2022, Abu\n",
      "Dhabi, United Arab Emirates, December 7-11, 2022,\n",
      "\n",
      "Question: What is the main topic of the document?\n",
      "Helpful Answer: The main topic of this document appears to be advancements in natural language processing techniques and their applications within various fields such as machine learning, information retrieval, and AI development. However, it's important to note that without specific details about each paper or section, I can't provide a more precise summary. To get deeper insights into any particular aspect, one would need to read through the full content carefully. \n",
      "\n",
      "Given the limited information provided, we cannot definitively state what \"the main topic\" refers to specifically unless there are additional relevant sections mentioned in the text. Therefore, based on the available data points here alone, my best response remains that while the papers cover diverse areas related to NLP, no single overarching theme is explicitly stated beyond general references to computational linguistics and artificial intelligence methods.\n"
     ]
    }
   ],
   "source": [
    "# 질문 예시\n",
    "# question = \"문서에서 설명하는 주요 내용은 무엇인가요?\"\n",
    "question = \"What is the main topic of the document?\"\n",
    "\n",
    "# 질문에 대한 답변 생성\n",
    "result = query_rag_pipeline(qa_chain, question)\n",
    "print(result[\"answer\"])\n",
    "# print(\"\\n참고 문서:\")\n",
    "# for doc in result[\"source_documents\"]:\n",
    "#     print(f\"- {doc.page_content[:200]}...\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de651283-6d23-43d6-9597-1fe335793726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25b4205-6dd8-4c9b-9dd1-2ae985dcb1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
